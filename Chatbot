# Title: ECFR Title 24 Chatbot (Streamlit + LangChain)
# Author: Zach's AI housing assistant

!pip install -q langchain openai chromadb tiktoken streamlit

import streamlit as st
from langchain.document_loaders import TextLoader
from langchain.vectorstores import Chroma
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.llms import OpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.schema import Document
import json
import os

# === STEP 1: CONFIGURATION ===
OPENAI_API_KEY = "sk-..."  # Replace with your actual key
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

DATA_PATH = "/content/cfr_title24_sections_parsed.jsonl"
FORMS_PATH = "/content/forms_index.jsonl"  # Optional HUD forms
CHROMA_PATH = "/content/chroma_db"

# === STEP 2: LOAD AND FORMAT THE DATA ===
documents = []

# Load CFR sections
with open(DATA_PATH, "r") as f:
    for line in f:
        entry = json.loads(line)
        text = f"{entry['section_number']} - {entry.get('section_heading', '')}\n\n{entry['text']}"
        metadata = {
            "section": entry["section_number"],
            "title": entry.get("section_heading"),
            "part": entry.get("part_heading"),
            "source_file": entry.get("file")
        }
        documents.append(Document(page_content=text, metadata=metadata))

# Load HUD forms/notices if available
if os.path.exists(FORMS_PATH):
    with open(FORMS_PATH, "r") as f:
        for line in f:
            entry = json.loads(line)
            text = f"HUD Form {entry['form_number']}\n\n{entry.get('description', 'No description')}"
            metadata = {
                "form_number": entry["form_number"],
                "title": entry.get("title", "HUD Form"),
                "path": entry.get("path"),
                "type": "HUD Form"
            }
            documents.append(Document(page_content=text, metadata=metadata))

# === STEP 3: EMBEDDING AND VECTORSTORE ===
embedding = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(documents, embedding, persist_directory=CHROMA_PATH)
retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

# === STEP 4: SETUP CONVERSATIONAL CHAIN ===
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
qa_chain = ConversationalRetrievalChain.from_llm(
    llm=OpenAI(temperature=0),
    retriever=retriever,
    memory=memory,
    return_source_documents=True
)

# === STEP 5: STREAMLIT INTERFACE ===
st.set_page_config(page_title="ECFR Title 24 GPT Bot", layout="wide")
st.title("ðŸ¤– ECFR Title 24 GPT Bot")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

query = st.text_input("Ask a question about CFR Title 24 or HUD forms:", key="user_input")

if query:
    result = qa_chain({"question": query, "chat_history": st.session_state.chat_history})
    st.markdown("### ðŸ’¬ Response")
    st.write(result["answer"])

    st.markdown("### ðŸ“„ Source Documents")
    for doc in result["source_documents"]:
        if doc.metadata.get("type") == "HUD Form":
            st.markdown(f"- **HUD Form {doc.metadata['form_number']}**: {doc.metadata['title']}")
        else:
            st.markdown(f"- **{doc.metadata['section']}**: {doc.metadata['title']} ({doc.metadata['part']})")

    st.session_state.chat_history.append((query, result["answer"]))
